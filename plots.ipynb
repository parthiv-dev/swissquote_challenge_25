{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46a90ec",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "# comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d818f2",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHS = 12*10\n",
    "\n",
    "# Define weights (original fund tickers)\n",
    "weights = {\n",
    "    \"AUTO.OL\": 0.019094, \"BKW.SW\": 0.050846, \"BMI\": 0.033615, \"CGNX\": 0.028368, \"CLH\": 0.038201,\n",
    "    \"CWST\": 0.047824, \"CWY.AX\": 0.038031, \"ECL\": 0.054767, \"ENEL.MI\": 0.063910, \"ENR.DE\": 0.023263,\n",
    "    \"FSLR\": 0.019741, \"GF.SW\": 0.035485, \"GFL\": 0.038149, \"GXO\": 0.028886, \"IBE.MC\": 0.066922,\n",
    "    \"KGX.DE\": 0.029591, \"MANH\": 0.032971, \"NEE\": 0.040971, \"ORSTED.CO\": 0.028671, \"SYM\": 0.011842,\n",
    "    \"TOM.OL\": 0.019474, \"VIE.PA\": 0.055726, \"VLTO\": 0.053097, \"WM\": 0.057568, \"XYL\": 0.048435, \"ZBRA\": 0.034552\n",
    "}\n",
    "\n",
    "weights = pd.Series(weights)\n",
    "\n",
    "# Define time range\n",
    "end_date = pd.Timestamp(\"2025-04-01\") # For consistency\n",
    "start_date = end_date - pd.DateOffset(months=MONTHS)\n",
    "\n",
    "# Benchmark tickers\n",
    "benchmark_tickers = [\"^GSPC\", \"^SSMI\", \"^DJI\"]\n",
    "basket_tickers = list(weights.index)\n",
    "all_tickers = basket_tickers + benchmark_tickers\n",
    "\n",
    "# Download data\n",
    "print(f\"Downloading {MONTHS} months of data...\")\n",
    "data = yf.download(all_tickers, start=start_date, end=end_date, auto_adjust=True, progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d75978b",
   "metadata": {},
   "source": [
    "## Clean Up Data\n",
    "\n",
    "- We are (currently) only interested in close\n",
    "- Deal with yfinance api...\n",
    "- Linear interpolation between missing values\n",
    "- Drop sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ead883",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of rows and columns\n",
    "print(f\"Data shape: {data['Close'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle multi-index if present (yfinance...)\n",
    "if isinstance(data.columns, pd.MultiIndex):\n",
    "    if 'Close' in data.columns.levels[0]:\n",
    "        data = data['Close']\n",
    "    elif 'Adj Close' in data.columns.levels[0]:\n",
    "        data = data['Adj Close']\n",
    "    else:\n",
    "        try:\n",
    "            data.columns = data.columns.droplevel(0)\n",
    "        except:\n",
    "            price_cols = [col for col in data.columns if col[0] in ['Close', 'Adj Close']]\n",
    "            if price_cols:\n",
    "                data = data[price_cols]\n",
    "                data.columns = data.columns.droplevel(0)\n",
    "            else:\n",
    "                data.columns = ['_'.join(col).strip() for col in data.columns.values]\n",
    "\n",
    "# Flatten remaining multi-index if needed\n",
    "if isinstance(data.columns, pd.MultiIndex):\n",
    "    data.columns = data.columns.droplevel(0)\n",
    "elif any(isinstance(col, tuple) for col in data.columns):\n",
    "    data.columns = [col[0] if isinstance(col, tuple) else col for col in data.columns]\n",
    "\n",
    "# Track interpolation and dropped data points\n",
    "original_shape = data.shape\n",
    "missing_before = data.isna().sum().sum()\n",
    "missing_percentage_before = 100 * missing_before / (original_shape[0] * original_shape[1])\n",
    "\n",
    "# Drop sparsely populated rows/columns\n",
    "print(\"Interpolating and cleaning data...\")\n",
    "data = data.dropna(axis=1, thresh=int(0.50 * len(data))) # Drop columns with >50% missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Calculate interpolation statistics\n",
    "missing_after = data.isna().sum().sum()\n",
    "interpolated_count = missing_before - missing_after\n",
    "interpolated_percentage = 100 * interpolated_count / (original_shape[0] * original_shape[1])\n",
    "\n",
    "# Calculate dropped data statistics\n",
    "dropped_cells = original_shape[0] * original_shape[1] - data.shape[0] * data.shape[1]\n",
    "dropped_percentage = 100 * dropped_cells / (original_shape[0] * original_shape[1])\n",
    "\n",
    "# Keep only tickers with valid data\n",
    "benchmark_tickers = [t for t in benchmark_tickers if t in data.columns]\n",
    "valid_tickers = data.columns.drop(benchmark_tickers, errors='ignore')\n",
    "valid_weights = weights[weights.index.isin(valid_tickers)]\n",
    "\n",
    "if valid_weights.empty:\n",
    "    raise ValueError(\"No valid tickers found after cleaning.\")\n",
    "\n",
    "# Re-normalize weights after cleaning\n",
    "valid_weights = valid_weights / valid_weights.sum()\n",
    "\n",
    "# Print summary of data cleaning process\n",
    "print(f\"\\nData cleaning summary:\")\n",
    "print(f\"Original data shape: {original_shape[0]} rows × {original_shape[1]} columns = {original_shape[0] * original_shape[1]} cells\")\n",
    "print(f\"Missing values before interpolation: {missing_before} cells ({missing_percentage_before:.2f}%)\")\n",
    "print(f\"Interpolated values: {interpolated_count} cells ({interpolated_percentage:.2f}%)\")\n",
    "print(f\"Still missing after interpolation: {missing_after} cells ({100 * missing_after / (original_shape[0] * original_shape[1]):.2f}%)\")\n",
    "print(f\"Dropped data: {dropped_cells} cells ({dropped_percentage:.2f}%)\")\n",
    "print(f\"Final data shape: {data.shape[0]} rows × {data.shape[1]} columns = {data.shape[0] * data.shape[1]} cells\")\n",
    "print(\"Final tickers:\", list(valid_weights.index))\n",
    "print(\"Final benchmark tickers:\", benchmark_tickers)\n",
    "print(\"Data cleaned and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00497b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of rows and columns\n",
    "print(f\"Data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15538ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe51c6",
   "metadata": {},
   "source": [
    "## Normalize Basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a141d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Basket (Fund) to 100 at the start of the period\n",
    "normalized_basket = data[valid_weights.index].divide(data[valid_weights.index].iloc[0]) * 100\n",
    "basket_index = normalized_basket.multiply(valid_weights, axis=1).sum(axis=1)\n",
    "\n",
    "# Normalize Benchmarks (S&P 500, SMI, DJ) to 100 at the start of the period\n",
    "normalized_benchmarks = {}\n",
    "for ticker in benchmark_tickers:\n",
    "    if ticker in data:\n",
    "        normalized_benchmarks[ticker] = data[ticker] / data[ticker].iloc[0] * 100\n",
    "        print(f\"Benchmark {ticker} normalized.\")\n",
    "    else:\n",
    "        print(f\"Benchmark ticker {ticker} not found in data after cleaning.\")\n",
    "# Normalize Basket (Fund) to 100 at the start of the period\n",
    "normalized_basket = data[valid_weights.index].divide(data[valid_weights.index].iloc[0]) * 100\n",
    "basket_index = normalized_basket.multiply(valid_weights, axis=1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31bee7c",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53882bc",
   "metadata": {},
   "source": [
    "### Basket vs Benchmarks\n",
    "\n",
    "We look at normalized returns and compare our basket to the benchmarks (S&P500, Dow Jones, SMI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f9e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the basket index and benchmarks\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.plot(basket_index, label='Vital Industries Basket', linewidth=2)\n",
    "\n",
    "# Plot each benchmark\n",
    "for ticker, normalized_benchmark in normalized_benchmarks.items():\n",
    "    plt.plot(normalized_benchmark, label=f'{ticker} Benchmark', linestyle='--')\n",
    "\n",
    "# Labels, title, and legend\n",
    "plt.title(f'Vital Industries Basket vs. Benchmarks (Last {int(MONTHS/12)} Years)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Normalized Index Value (Base = 100)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28701d1f",
   "metadata": {},
   "source": [
    "### Correlation: Basket vs Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617af511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data (basket + benchmarks) for correlation analysis\n",
    "combined_data = pd.concat([basket_index] + list(normalized_benchmarks.values()), axis=1)\n",
    "combined_data.columns = ['Basket'] + [ticker for ticker in benchmark_tickers]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = combined_data.corr()\n",
    "\n",
    "# Plotting correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5, cbar=True)\n",
    "plt.title('Correlation Matrix: Basket vs Benchmarks')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defcb0e6",
   "metadata": {},
   "source": [
    "### Regression Metrics: Alpha, Beta, and R-squared\n",
    "\n",
    "**TLDR Explanation:**\n",
    "\n",
    "* **Alpha:**  Measures the basket's excess return compared to the benchmark.\n",
    "    * Positive Alpha: Basket outperformed the benchmark (risk-adjusted).\n",
    "    * Negative Alpha: Basket underperformed the benchmark (risk-adjusted).\n",
    "    * Alpha of 0: Basket performed as expected given the benchmark.\n",
    "\n",
    "* **Beta:**  Measures the basket's volatility relative to the benchmark.\n",
    "    * Beta = 1: Basket's price tends to move in the same direction and magnitude as the benchmark.\n",
    "    * Beta > 1: Basket is more volatile than the benchmark.\n",
    "    * Beta < 1: Basket is less volatile than the benchmark.\n",
    "\n",
    "* **R-squared:** Measures how well the benchmark explains the basket's movements.\n",
    "    * R-squared close to 1:  Benchmark explains most of the basket's price variations.\n",
    "    * R-squared close to 0: Benchmark explains very little of the basket's price variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14fe02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regression_metrics(basket_returns, benchmark_returns, periods=252):\n",
    "    benchmark_returns = sm.add_constant(benchmark_returns)\n",
    "    model = sm.OLS(basket_returns, benchmark_returns).fit()\n",
    "    daily_alpha = model.params[0]\n",
    "    # Annualize alpha (similar to annualizing returns)\n",
    "    alpha = daily_alpha * periods\n",
    "    beta = model.params[1]\n",
    "    r_squared = model.rsquared\n",
    "    return alpha, beta, r_squared\n",
    "\n",
    "# Dictionaries to store results\n",
    "alpha_values = {}\n",
    "beta_values = {}\n",
    "r_squared_values = {}\n",
    "\n",
    "# Loop over each benchmark\n",
    "for benchmark_name, normalized_benchmark in normalized_benchmarks.items():\n",
    "    basket_returns = basket_index.pct_change().dropna()\n",
    "    benchmark_prices_raw = data[benchmark_name]\n",
    "    benchmark_returns = benchmark_prices_raw.pct_change().dropna()\n",
    "\n",
    "    # Align the data by date\n",
    "    combined = pd.concat([basket_returns, benchmark_returns], axis=1).dropna()\n",
    "    aligned_basket = combined.iloc[:, 0]\n",
    "    aligned_benchmark = combined.iloc[:, 1]\n",
    "\n",
    "    # Compute alpha, beta, and R²\n",
    "    alpha, beta, r_squared = compute_regression_metrics(aligned_basket, aligned_benchmark) \n",
    "\n",
    "    # Store the results\n",
    "    alpha_values[benchmark_name] = alpha\n",
    "    beta_values[benchmark_name] = beta\n",
    "    r_squared_values[benchmark_name] = r_squared\n",
    "\n",
    "    print(f\"{benchmark_name}: Alpha={alpha:.4f}, Beta={beta:.4f}, R²={r_squared:.4f}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 12), sharex=True)\n",
    "\n",
    "# Alpha Plot\n",
    "axes[0].bar(alpha_values.keys(), alpha_values.values(), color='orange')\n",
    "axes[0].set_ylabel('Alpha')\n",
    "axes[0].set_title('Basket Alpha vs Each Benchmark')\n",
    "axes[0].axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "# Beta Plot\n",
    "axes[1].bar(beta_values.keys(), beta_values.values(), color='dodgerblue')\n",
    "axes[1].set_ylabel('Beta')\n",
    "axes[1].set_title('Basket Beta vs Each Benchmark')\n",
    "axes[1].axhline(1, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "# R² Plot\n",
    "axes[2].bar(r_squared_values.keys(), r_squared_values.values(), color='seagreen')\n",
    "axes[2].set_ylabel('R²')\n",
    "axes[2].set_title('Basket R² vs Each Benchmark')\n",
    "axes[2].set_ylim(0, 1)\n",
    "axes[2].axhline(0.5, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "# Final touches\n",
    "plt.xlabel('Benchmark')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacb5f1d",
   "metadata": {},
   "source": [
    "### Sharpe Ratio Analysis\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "The Sharpe Ratio is a measure of risk-adjusted return. It indicates how much excess return an investor receives for taking on additional risk.  A higher Sharpe Ratio is better, indicating more return for the same amount of risk.\n",
    "\n",
    "**Calculation:**\n",
    "\n",
    "Sharpe Ratio is calculated as:\n",
    "\n",
    "**(Average Portfolio Return - Risk-Free Rate) / Standard Deviation of Portfolio Returns**\n",
    "\n",
    "In this context, we assume a risk-free rate of 0 for simplicity.  We calculate the Sharpe Ratio for our \"Vital Industries Basket\" and compare it to the Sharpe Ratios of the benchmark indices to understand how our basket's risk-adjusted return compares to the broader market.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "* **Higher Sharpe Ratio:** Indicates better risk-adjusted performance. The portfolio is generating more return per unit of risk taken.\n",
    "* **Lower Sharpe Ratio:** Indicates worse risk-adjusted performance. The portfolio is generating less return per unit of risk taken.\n",
    "* **Comparison:** By comparing the Sharpe Ratio of the basket to the benchmarks, we can assess whether the basket provides a superior risk-adjusted return compared to simply investing in the market benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a12f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the annualized Sharpe Ratio\n",
    "def sharpe_ratio(returns, risk_free_rate=0, periods=252):\n",
    "    excess_returns = returns - risk_free_rate\n",
    "    # Annualize the ratio\n",
    "    return np.mean(excess_returns) * periods / (np.std(excess_returns) * np.sqrt(periods))\n",
    "\n",
    "\n",
    "# --- Corrected Basket Sharpe Ratio Calculation ---\n",
    "# Calculate basket returns from the RAW prices of its constituents\n",
    "basket_prices_raw = data[valid_weights.index] # Get raw prices for basket constituents\n",
    "basket_daily_returns_raw = basket_prices_raw.pct_change().dropna() # Daily returns for each constituent\n",
    "basket_portfolio_returns_raw = (basket_daily_returns_raw * valid_weights).sum(axis=1) # Portfolio returns\n",
    "basket_sharpe = sharpe_ratio(basket_portfolio_returns_raw) # Sharpe Ratio from RAW portfolio returns\n",
    "\n",
    "# Calculate basket Sharpe Ratio (annualized)\n",
    "basket_sharpe = sharpe_ratio(basket_portfolio_returns_raw)\n",
    "\n",
    "# Calculate benchmark Sharpe Ratios (annualized)\n",
    "benchmark_sharpe = {}\n",
    "for ticker in benchmark_tickers:\n",
    "    benchmark_prices_raw = data[ticker]\n",
    "    benchmark_returns = benchmark_prices_raw.pct_change().dropna()\n",
    "    benchmark_sharpe[ticker] = sharpe_ratio(benchmark_returns)\n",
    "\n",
    "\n",
    "# Calculate benchmark Sharpe Ratios (Correct - No Change Needed)\n",
    "benchmark_sharpe = {}\n",
    "for ticker in benchmark_tickers:\n",
    "    benchmark_prices_raw = data[ticker]\n",
    "    benchmark_returns = benchmark_prices_raw.pct_change().dropna()\n",
    "    benchmark_sharpe[ticker] = sharpe_ratio(benchmark_returns)\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    'Sharpe Ratio': [basket_sharpe] + list(benchmark_sharpe.values()),\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for easier viewing\n",
    "metrics_df = pd.DataFrame(metrics, index=['Basket'] + benchmark_tickers)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=metrics_df.index, y=metrics_df['Sharpe Ratio'], palette='Blues')\n",
    "plt.title('Sharpe Ratio Comparison')\n",
    "plt.ylabel('Sharpe Ratio')\n",
    "plt.xlabel('')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09991d73",
   "metadata": {},
   "source": [
    "### Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342186f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk-Return Factor Analysis - Comprehensive 2x2 visualization\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "gs = fig.add_gridspec(2, 2, height_ratios=[1, 1], width_ratios=[1, 1])\n",
    "\n",
    "# 1. Alpha Plot (Top Left)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.bar(alpha_values.keys(), alpha_values.values(), color='orange')\n",
    "ax1.set_ylabel('Alpha')\n",
    "ax1.set_title('Excess Return (Alpha)', fontsize=14, fontweight='bold')\n",
    "ax1.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Beta Plot (Top Right)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.bar(beta_values.keys(), beta_values.values(), color='dodgerblue')\n",
    "ax2.set_ylabel('Beta')\n",
    "ax2.set_title('Market Sensitivity (Beta)', fontsize=14, fontweight='bold')\n",
    "ax2.axhline(1, color='gray', linestyle='--', linewidth=1)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. R-squared Plot (Bottom Left)\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax3.bar(r_squared_values.keys(), r_squared_values.values(), color='seagreen')\n",
    "ax3.set_ylabel('R²')\n",
    "ax3.set_title('Market Correlation (R²)', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.axhline(0.5, color='gray', linestyle='--', linewidth=1)\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Sharpe Ratio Plot (Bottom Right)\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "sharpe_data = pd.DataFrame({\n",
    "    'Sharpe Ratio': [basket_sharpe] + list(benchmark_sharpe.values())\n",
    "}, index=['Basket'] + benchmark_tickers)\n",
    "sns.barplot(x=sharpe_data.index, y='Sharpe Ratio', data=sharpe_data, palette=['green'] + ['steelblue']*len(benchmark_tickers), ax=ax4)\n",
    "ax4.set_ylabel('Sharpe Ratio')\n",
    "ax4.set_title('Risk-Adjusted Returns (Sharpe Ratio)', fontsize=14, fontweight='bold')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add overall title and description\n",
    "plt.suptitle('Comprehensive Risk-Return Factor Analysis', fontsize=18, y=0.98)\n",
    "\n",
    "# Add a text box with key insights\n",
    "textstr = (\n",
    "    \"KEY INSIGHTS:\\n\"\n",
    "    f\"• Alpha: Basket outperforms benchmarks by {np.mean(list(alpha_values.values())):.2f}% annually (risk-adjusted)\\n\"\n",
    "    f\"• Beta: Basket shows {np.mean(list(beta_values.values())):.2f} average sensitivity (less volatile than market)\\n\"\n",
    "    f\"• Sharpe: {(basket_sharpe/np.mean(list(benchmark_sharpe.values()))-1)*100:.1f}% better risk-adjusted returns vs benchmarks\\n\"\n",
    "    f\"• Correlation: {np.mean(list(r_squared_values.values()))*100:.1f}% of returns explained by market movements\"\n",
    ")\n",
    "\n",
    "fig.text(0.5, 0.02, textstr, fontsize=12, ha='center', va='bottom', \n",
    "         bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.06, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb212be0",
   "metadata": {},
   "source": [
    "### Multi-Dimensional Portfolio Component Analysis\n",
    "\n",
    "This section provides a comprehensive analysis of how individual stocks contribute to the basket's overall performance through an enhanced multi-factor analytical framework. Unlike traditional contribution analysis that simply looks at weighted returns, this approach incorporates:\n",
    "\n",
    "1. **Risk-Adjusted Contribution**: By subtracting the risk-free rate (US 10Y Treasury at ~2%), we measure the true economic value created by each stock beyond what a risk-free investment would provide. This reveals which holdings are genuinely creating alpha.\n",
    "\n",
    "2. **Temporal Contribution Patterns**: The analysis segments contribution across multiple timeframes:\n",
    "   - Total historical contribution (entire analysis period)\n",
    "   - Recent dynamics (last 24 months)\n",
    "   - Early period performance (first half of dataset)\n",
    "   \n",
    "   This segmentation helps identify stocks with consistent performance versus those whose contribution is concentrated in specific time periods.\n",
    "\n",
    "3. **Market Regime Sensitivity**: Using a 30-day rolling average of S&P 500 returns as a market sentiment indicator, the analysis categorizes periods as \"bull market\" (positive trend) or \"bear market\" (negative trend) phases. This reveals which stocks provide offense (outperformance in bull markets) versus defense (protection during downturns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Stock Contribution Analysis - Focused Version\n",
    "# Calculate daily returns for each stock in the basket\n",
    "basket_data = data[valid_weights.index]\n",
    "daily_returns = basket_data.pct_change().dropna()\n",
    "\n",
    "# Define the risk-free rate (US 10Y Treasury average ~2%)\n",
    "annual_risk_free_rate = 0.02\n",
    "daily_risk_free_rate = annual_risk_free_rate / 252\n",
    "\n",
    "# Calculate the excess returns (over risk-free rate)\n",
    "excess_daily_returns = daily_returns.subtract(daily_risk_free_rate)\n",
    "weighted_excess_returns = excess_daily_returns.multiply(valid_weights, axis=1)\n",
    "\n",
    "# Create a figure with multiple subplots - simplified layout\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "gs = fig.add_gridspec(2, 2, height_ratios=[1, 1])\n",
    "\n",
    "# 1. OVERALL CONTRIBUTION ANALYSIS (TOP ROW)\n",
    "# Calculate the cumulative return for each stock's contribution (interest-rate adjusted)\n",
    "cumulative_contribution = (1 + weighted_excess_returns).cumprod()\n",
    "total_contribution = cumulative_contribution.iloc[-1] - 1\n",
    "sorted_contribution = total_contribution.sort_values(ascending=False)\n",
    "\n",
    "# Create a color map based on contribution magnitude\n",
    "cmap = plt.cm.RdYlGn  # Red-Yellow-Green colormap\n",
    "norm = plt.Normalize(sorted_contribution.min(), sorted_contribution.max())\n",
    "colors = [cmap(norm(value)) for value in sorted_contribution]\n",
    "\n",
    "# Plot the overall contribution\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "bars = ax1.bar(sorted_contribution.index, sorted_contribution.values, color=colors)\n",
    "ax1.set_title('Total Stock Contribution to Basket (Interest Rate Adjusted)', fontsize=14)\n",
    "ax1.set_ylabel('Excess Contribution')\n",
    "ax1.set_xticklabels(sorted_contribution.index, rotation=90)\n",
    "ax1.axhline(y=0, color='gray', linestyle='--', alpha=0.7)\n",
    "ax1.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Plot cumulative contribution as a line graph\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "# Stack the top 5 and bottom 5 contributors\n",
    "top5 = sorted_contribution.nlargest(5).index\n",
    "bottom5 = sorted_contribution.nsmallest(5).index\n",
    "key_stocks = list(top5) + list(bottom5)\n",
    "cumulative_contribution[key_stocks].plot(ax=ax2, linewidth=2)\n",
    "ax2.set_title('Cumulative Contribution Over Time (Top and Bottom Contributors)', fontsize=14)\n",
    "ax2.set_ylabel('Cumulative Excess Return')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(loc='best')\n",
    "\n",
    "# 3. MARKET REGIME ANALYSIS (BOTTOM ROW)\n",
    "# Identify bull vs bear market periods using benchmark\n",
    "benchmark_returns = data[benchmark_tickers[0]].pct_change().dropna()  # using first benchmark (S&P500)\n",
    "rolling_window = 30  # 30-day rolling window\n",
    "rolling_returns = benchmark_returns.rolling(window=rolling_window).mean()\n",
    "bull_market = rolling_returns > 0\n",
    "bear_market = rolling_returns <= 0\n",
    "\n",
    "# Calculate contribution during bull and bear markets\n",
    "bull_contrib = weighted_excess_returns[bull_market].sum()\n",
    "bear_contrib = weighted_excess_returns[bear_market].sum()\n",
    "regime_contrib = pd.DataFrame({\n",
    "    'Bull Market': bull_contrib,\n",
    "    'Bear Market': bear_contrib\n",
    "}).sort_values(by='Bull Market', ascending=False)\n",
    "\n",
    "# Plot market regime contribution\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "regime_contrib.plot(kind='bar', ax=ax3, width=0.8, color=['green', 'red'])\n",
    "ax3.set_title(f'Stock Contribution by Market Regime ({rolling_window}-day Moving Average)', fontsize=14)\n",
    "ax3.set_ylabel('Contribution')\n",
    "ax3.axhline(y=0, color='gray', linestyle='--', alpha=0.7)\n",
    "ax3.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "ax3.legend(['Bull Market', 'Bear Market'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display summary statistics\n",
    "summary = pd.DataFrame({\n",
    "    'Total Contribution': total_contribution,\n",
    "    'Bull Market': bull_contrib,\n",
    "    'Bear Market': bear_contrib,\n",
    "    'Weight': valid_weights\n",
    "}).sort_values(by='Total Contribution', ascending=False)\n",
    "\n",
    "# Calculate risk-adjusted contribution (contribution per unit of weight)\n",
    "summary['Contribution/Weight'] = summary['Total Contribution'] / summary['Weight']\n",
    "\n",
    "print(\"Stock Contribution Summary (Interest Rate Adjusted):\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472c1cf",
   "metadata": {},
   "source": [
    "### Monte Carlo Simulation\n",
    "\n",
    "Includes confidence levels up to 3-sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd17b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Monte Carlo Simulation with normalized starting values\n",
    "n_simulations = 20000  # Reduced number of simulations for better performance\n",
    "n_years = 3  # Forecast for X years as requested\n",
    "n_days = int(252 * n_years)  # Trading days in X years (252 trading days per year)\n",
    "\n",
    "# Store the original values for calculating true growth rates later\n",
    "original_values = {\n",
    "    'Basket': basket_index.iloc[-1],\n",
    "}\n",
    "for ticker in benchmark_tickers:\n",
    "    original_values[ticker] = normalized_benchmarks[ticker].iloc[-1]\n",
    "\n",
    "# Create dictionary to store all simulation results (basket + benchmarks)\n",
    "# All starting at 100 for fair comparison\n",
    "# Use a distinct color for each benchmark\n",
    "benchmark_colors = {\n",
    "    '^GSPC': '#8B4513',  # S&P 500 - brown\n",
    "    '^SSMI': '#4B0082',  # SMI - indigo\n",
    "    '^DJI': '#191970',   # Dow Jones - navy blue\n",
    "}\n",
    "\n",
    "simulation_results = {\n",
    "    'Basket': {\n",
    "        'original_value': original_values['Basket'],\n",
    "        'initial_value': 100,  # All start at 100\n",
    "        'paths': np.zeros((n_simulations, n_days)),\n",
    "        'color': 'green'  # Keep basket green\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add benchmarks to simulation with unique colors\n",
    "for ticker in benchmark_tickers:\n",
    "    simulation_results[ticker] = {\n",
    "        'original_value': original_values[ticker],\n",
    "        'initial_value': 100,  # All start at 100\n",
    "        'paths': np.zeros((n_simulations, n_days)),\n",
    "        'color': benchmark_colors.get(ticker, '#555555')  # Use specific colors from mapping\n",
    "    }\n",
    "\n",
    "# Run Monte Carlo simulation for basket and benchmarks\n",
    "for asset_name, asset_data in simulation_results.items():\n",
    "    # Get historical data for the asset\n",
    "    if asset_name == 'Basket':\n",
    "        returns_series = basket_index.pct_change().dropna()\n",
    "    else:\n",
    "        returns_series = normalized_benchmarks[asset_name].pct_change().dropna()\n",
    "    \n",
    "    # Calculate historical stats\n",
    "    historical_returns = returns_series.mean()\n",
    "    historical_volatility = returns_series.std()\n",
    "    \n",
    "    # Generate simulations\n",
    "    for i in range(n_simulations):\n",
    "        daily_returns_simulated = np.random.normal(historical_returns, historical_volatility, n_days)\n",
    "        cumulative_returns = np.cumprod(1 + daily_returns_simulated)\n",
    "        asset_data['paths'][i, :] = asset_data['initial_value'] * cumulative_returns\n",
    "\n",
    "    # Calculate statistics for each asset\n",
    "    asset_data['mean_path'] = asset_data['paths'].mean(axis=0)\n",
    "    asset_data['sigma'] = asset_data['paths'].std(axis=0)\n",
    "\n",
    "# Create a more sophisticated plot\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "# Plot benchmark simulations first (so they're in the background)\n",
    "for asset_name, asset_data in simulation_results.items():\n",
    "    if asset_name != 'Basket':  # Plot benchmarks first\n",
    "        # Plot some sample paths for benchmarks (reduced number for clarity)\n",
    "        # Make paths extremely faint\n",
    "        for i in range(0, n_simulations, 100):  # Plot only every 100th path - much less visual clutter\n",
    "            plt.plot(asset_data['paths'][i, :], color=asset_data['color'], alpha=0.01, linewidth=0.3)\n",
    "        \n",
    "        # Plot the mean path for benchmarks with distinct colors and labels\n",
    "        plt.plot(asset_data['mean_path'], color=asset_data['color'], alpha=0.9, \n",
    "                 linestyle='--', linewidth=2.0, \n",
    "                 label=f'{asset_name} Expected')\n",
    "\n",
    "# Plot basket simulations on top (making sure they stand out)\n",
    "basket_data = simulation_results['Basket']\n",
    "# Plot basket sample paths with very low alpha for clarity\n",
    "for i in range(0, n_simulations, 50):  # Even fewer paths for less clutter\n",
    "    plt.plot(basket_data['paths'][i, :], color='blue', alpha=0.1, linewidth=0.3)\n",
    "\n",
    "# Plot confidence bands for basket only\n",
    "plt.fill_between(range(n_days), \n",
    "                 basket_data['mean_path'] - basket_data['sigma'], \n",
    "                 basket_data['mean_path'] + basket_data['sigma'],\n",
    "                 color='skyblue', alpha=0.4, label='Basket 68% Confidence')\n",
    "\n",
    "plt.fill_between(range(n_days), \n",
    "                 basket_data['mean_path'] - 2*basket_data['sigma'], \n",
    "                 basket_data['mean_path'] + 2*basket_data['sigma'],\n",
    "                 color='skyblue', alpha=0.3, label='Basket 95% Confidence')\n",
    "\n",
    "# Plot the mean path for basket prominently\n",
    "plt.plot(basket_data['mean_path'], color='green', linewidth=2.5, \n",
    "         label='Vital Industries Basket (Expected)')\n",
    "\n",
    "# Calculate expected final values and growth rates for comparison\n",
    "final_values_normalized = {name: data['mean_path'][-1] for name, data in simulation_results.items()}\n",
    "growth_rates = {name: (val/100 - 1)*100 for name, val in final_values_normalized.items()}\n",
    "print(f\"Projected {n_years}-year values (normalized to start at 100):\")\n",
    "for name, value in final_values_normalized.items():\n",
    "    print(f\"{name}: {value:.2f} (Growth: {growth_rates[name]:.1f}%)\")\n",
    "\n",
    "# X-axis with year markers instead of days\n",
    "year_ticks = [0]\n",
    "year_labels = ['Now']\n",
    "for i in range(1, n_years + 1):\n",
    "    year_ticks.append(i * 252)\n",
    "    year_labels.append(f'+{i}yr')\n",
    "\n",
    "plt.xticks(year_ticks, year_labels)\n",
    "\n",
    "# Format the plot\n",
    "plt.title(f'Monte Carlo Forecast: Vital Industries Basket vs Benchmarks (Next {n_years} Years)', fontsize=16)\n",
    "plt.xlabel('Time Horizon', fontsize=12)\n",
    "plt.ylabel('Normalized Value (Base = 100)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add a text box highlighting the basket's outperformance\n",
    "mean_benchmark_growth = np.mean([growth_rates[b] for b in benchmark_tickers])\n",
    "outperformance = growth_rates['Basket'] - mean_benchmark_growth\n",
    "avg_beta = np.mean([beta_values[b] for b in benchmark_tickers])  # Average beta from earlier calculations\n",
    "\n",
    "textstr = (f\"Vital Industries Basket Projection:\\n\"\n",
    "           f\"• Expected {n_years}-year return: {growth_rates['Basket']:.1f}%\\n\"\n",
    "           f\"• Outperformance vs benchmarks: {outperformance:.1f} percentage points\\n\"\n",
    "           f\"• Lower volatility (β≈{avg_beta:.2f}) with higher returns\")\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.7)\n",
    "plt.text(0.02, 0.97, textstr, transform=plt.gca().transAxes, fontsize=12,\n",
    "         verticalalignment='top', bbox=props)\n",
    "\n",
    "# Create a more prominent legend with distinct colors\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, frameon=True, fancybox=True, shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb940a",
   "metadata": {},
   "source": [
    "### Enhanced Risk-Return Analysis: Lower Volatility with Higher Returns\n",
    "\n",
    "This section analyzes how the Vital Industries Basket achieves both lower volatility and higher returns compared to the S&P 500 benchmark. This favorable risk-return profile represents the \"holy grail\" of investing - generating superior returns while exposing investors to less risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4258831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk-Return Analysis: Lower Volatility with Higher Returns\n",
    "from scipy.stats import norm\n",
    "\n",
    "# 1. Calculate annualized metrics for our basket and S&P 500\n",
    "sp500_ticker = \"^GSPC\"  # S&P 500 ticker\n",
    "\n",
    "# Calculate annualized returns and volatility\n",
    "basket_returns_series = basket_index.pct_change().dropna()\n",
    "sp500_returns_series = normalized_benchmarks[sp500_ticker].pct_change().dropna()\n",
    "\n",
    "# Ensure date alignment for fair comparison\n",
    "common_dates = basket_returns_series.index.intersection(sp500_returns_series.index)\n",
    "basket_returns_aligned = basket_returns_series.loc[common_dates]\n",
    "sp500_returns_aligned = sp500_returns_series.loc[common_dates]\n",
    "\n",
    "# Calculate key metrics\n",
    "annual_factor = 252  # Trading days in a year\n",
    "metrics = {\n",
    "    \"Basket\": {\n",
    "        \"Annualized Return (%)\": basket_returns_aligned.mean() * annual_factor * 100,\n",
    "        \"Volatility (%)\": basket_returns_aligned.std() * np.sqrt(annual_factor) * 100,\n",
    "        \"Sharpe Ratio\": sharpe_ratio(basket_returns_aligned),\n",
    "        \"Max Drawdown (%)\": (basket_index.loc[common_dates] / basket_index.loc[common_dates].cummax() - 1).min() * 100,\n",
    "        \"Data\": basket_returns_aligned,\n",
    "        \"Prices\": basket_index.loc[common_dates]\n",
    "    },\n",
    "    \"S&P 500\": {\n",
    "        \"Annualized Return (%)\": sp500_returns_aligned.mean() * annual_factor * 100,\n",
    "        \"Volatility (%)\": sp500_returns_aligned.std() * np.sqrt(annual_factor) * 100,\n",
    "        \"Sharpe Ratio\": sharpe_ratio(sp500_returns_aligned),\n",
    "        \"Max Drawdown (%)\": (normalized_benchmarks[sp500_ticker].loc[common_dates] / \n",
    "                           normalized_benchmarks[sp500_ticker].loc[common_dates].cummax() - 1).min() * 100,\n",
    "        \"Data\": sp500_returns_aligned,\n",
    "        \"Prices\": normalized_benchmarks[sp500_ticker].loc[common_dates]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create multi-part figure to showcase the risk-return advantages\n",
    "fig = plt.figure(figsize=(24, 14))\n",
    "gs = fig.add_gridspec(3, 2, height_ratios=[1.2, 1, 1.2])\n",
    "\n",
    "# 1. PART 1: Risk-Return Scatterplot (Top Left)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "# Create risk-return scatter plot\n",
    "x_vals = [metrics[k][\"Volatility (%)\"] for k in metrics]\n",
    "y_vals = [metrics[k][\"Annualized Return (%)\"] for k in metrics]\n",
    "colors = ['green', 'firebrick']\n",
    "labels = list(metrics.keys())\n",
    "\n",
    "# Plot the data points\n",
    "ax1.scatter(x_vals, y_vals, s=150, c=colors, alpha=0.8, edgecolors='black')\n",
    "\n",
    "# Add labels to each point\n",
    "for i, txt in enumerate(labels):\n",
    "    ax1.annotate(txt, (x_vals[i], y_vals[i]), \n",
    "                xytext=(7, 5), textcoords='offset points', \n",
    "                fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add a diagonal line representing equal risk-reward\n",
    "min_val = min(min(x_vals), min(y_vals)) * 0.9\n",
    "max_val = max(max(x_vals), max(y_vals)) * 1.1\n",
    "ax1.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.3)\n",
    "\n",
    "# Shade the \"optimal\" region (higher return, lower risk)\n",
    "optimal_region_x = [0, x_vals[1], x_vals[1], 0]\n",
    "optimal_region_y = [y_vals[0], y_vals[0], max_val*1.1, max_val*1.1]\n",
    "ax1.fill(optimal_region_x, optimal_region_y, alpha=0.1, color='green')\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel('Annualized Volatility (%)', fontsize=12)\n",
    "ax1.set_ylabel('Annualized Return (%)', fontsize=12)\n",
    "ax1.set_title('Risk-Return Profile: Vital Industries Basket vs S&P 500', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(min_val, max_val)\n",
    "ax1.set_ylim(min_val, max_val)\n",
    "\n",
    "# Add \"Better\" annotation to the optimal region\n",
    "ax1.annotate(\"BETTER\", xy=(min_val*1.5, max_val*0.9), \n",
    "            fontsize=14, color='green', alpha=0.7, fontweight='bold')\n",
    "\n",
    "# 2. PART 2: Return Distribution Comparison (Top Right)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "# Kernel density estimation for return distributions\n",
    "basket_kde = sns.kdeplot(metrics[\"Basket\"][\"Data\"]*100, label='Basket', \n",
    "                        color='green', ax=ax2, linewidth=2)\n",
    "sp500_kde = sns.kdeplot(metrics[\"S&P 500\"][\"Data\"]*100, label='S&P 500', \n",
    "                       color='firebrick', ax=ax2, linewidth=2)\n",
    "\n",
    "# Mark the means\n",
    "ax2.axvline(metrics[\"Basket\"][\"Data\"].mean()*100, color='green', linestyle='--')\n",
    "ax2.axvline(metrics[\"S&P 500\"][\"Data\"].mean()*100, color='firebrick', linestyle='--')\n",
    "\n",
    "# Add a legend and labels\n",
    "ax2.set_xlabel('Daily Return (%)', fontsize=12)\n",
    "ax2.set_ylabel('Density', fontsize=12)\n",
    "ax2.set_title('Return Distribution Comparison', fontsize=14)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations for the standard deviations\n",
    "basket_std = metrics[\"Basket\"][\"Data\"].std()*100\n",
    "sp500_std = metrics[\"S&P 500\"][\"Data\"].std()*100\n",
    "ax2.annotate(f\"Basket σ: {basket_std:.2f}%\", \n",
    "            xy=(0.05, 0.9), xycoords='axes fraction', \n",
    "            color='green', fontsize=12)\n",
    "ax2.annotate(f\"S&P 500 σ: {sp500_std:.2f}%\", \n",
    "            xy=(0.05, 0.85), xycoords='axes fraction', \n",
    "            color='firebrick', fontsize=12)\n",
    "\n",
    "# 3. PART 3: Rolling Volatility Comparison (Middle Row)\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "\n",
    "# Calculate rolling volatilities (annualized)\n",
    "window = 60  # 3-month window (approximately)\n",
    "basket_rolling_vol = basket_returns_aligned.rolling(window=window).std() * np.sqrt(annual_factor) * 100\n",
    "sp500_rolling_vol = sp500_returns_aligned.rolling(window=window).std() * np.sqrt(annual_factor) * 100\n",
    "\n",
    "# Plot rolling volatilities\n",
    "ax3.plot(basket_rolling_vol, color='green', linewidth=2, label=f'Basket {window}-day Rolling Volatility')\n",
    "ax3.plot(sp500_rolling_vol, color='firebrick', linewidth=2, label=f'S&P 500 {window}-day Rolling Volatility')\n",
    "\n",
    "# Calculate and display the percentage of time basket has lower volatility\n",
    "lower_vol_pct = (basket_rolling_vol < sp500_rolling_vol).mean() * 100\n",
    "ax3.set_title(f'Rolling {window}-day Volatility Comparison\\n(Basket has lower volatility {lower_vol_pct:.1f}% of the time)', fontsize=14)\n",
    "ax3.set_ylabel('Annualized Volatility (%)', fontsize=12)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend(loc='upper left')\n",
    "\n",
    "# Highlight volatility spike periods\n",
    "vol_diff = basket_rolling_vol - sp500_rolling_vol\n",
    "ax3.fill_between(vol_diff.index, 0, vol_diff,\n",
    "                where=vol_diff < 0, color='green', alpha=0.15,\n",
    "                label='Basket Volatility Advantage')\n",
    "ax3.fill_between(vol_diff.index, 0, vol_diff,\n",
    "                where=vol_diff > 0, color='red', alpha=0.15,\n",
    "                label='S&P 500 Volatility Advantage')\n",
    "\n",
    "# 4. PART 4A: Drawdown Analysis (Bottom Left)\n",
    "ax4a = fig.add_subplot(gs[2, 0])\n",
    "\n",
    "# Calculate rolling drawdowns\n",
    "basket_drawdown = metrics[\"Basket\"][\"Prices\"] / metrics[\"Basket\"][\"Prices\"].cummax() - 1\n",
    "sp500_drawdown = metrics[\"S&P 500\"][\"Prices\"] / metrics[\"S&P 500\"][\"Prices\"].cummax() - 1\n",
    "\n",
    "# Plot drawdowns\n",
    "ax4a.plot(basket_drawdown*100, color='green', linewidth=2, label='Basket Drawdown')\n",
    "ax4a.plot(sp500_drawdown*100, color='firebrick', linewidth=2, label='S&P 500 Drawdown')\n",
    "ax4a.fill_between(basket_drawdown.index, 0, basket_drawdown*100, color='green', alpha=0.15)\n",
    "ax4a.fill_between(sp500_drawdown.index, 0, sp500_drawdown*100, color='firebrick', alpha=0.15)\n",
    "\n",
    "ax4a.set_title('Drawdown Comparison', fontsize=14)\n",
    "ax4a.set_ylabel('Drawdown (%)', fontsize=12)\n",
    "ax4a.grid(True, alpha=0.3)\n",
    "ax4a.legend(loc='lower right')\n",
    "\n",
    "# Add annotations for max drawdowns\n",
    "ax4a.annotate(f\"Basket Max DD: {metrics['Basket']['Max Drawdown (%)']:.1f}%\", \n",
    "             xy=(0.05, 0.05), xycoords='axes fraction', \n",
    "             color='green', fontsize=12)\n",
    "ax4a.annotate(f\"S&P 500 Max DD: {metrics['S&P 500']['Max Drawdown (%)']:.1f}%\", \n",
    "             xy=(0.05, 0.1), xycoords='axes fraction', \n",
    "             color='firebrick', fontsize=12)\n",
    "\n",
    "# 5. PART 4B: Stress Test Analysis (Bottom Right)\n",
    "ax4b = fig.add_subplot(gs[2, 1])\n",
    "\n",
    "# Find worst periods for S&P 500\n",
    "worst_periods = sp500_returns_aligned.rolling(window=30).sum().sort_values().index[:5]\n",
    "\n",
    "# Compare performance during these periods\n",
    "stress_results = []\n",
    "for date in worst_periods:\n",
    "    end_date = date\n",
    "    start_date = end_date - pd.DateOffset(days=30)\n",
    "    if start_date in common_dates:\n",
    "        period_sp500 = sp500_returns_aligned.loc[start_date:end_date].sum() * 100\n",
    "        period_basket = basket_returns_aligned.loc[start_date:end_date].sum() * 100\n",
    "        stress_results.append((start_date.strftime('%Y-%m'), end_date.strftime('%Y-%m'), \n",
    "                              period_sp500, period_basket))\n",
    "\n",
    "# Create a bar chart to compare performance in stress periods\n",
    "if stress_results:\n",
    "    periods = [f\"{s} to\\n{e}\" for s, e, _, _ in stress_results]\n",
    "    sp500_stress = [sp for _, _, sp, _ in stress_results]\n",
    "    basket_stress = [b for _, _, _, b in stress_results]\n",
    "    \n",
    "    x = np.arange(len(periods))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax4b.bar(x - width/2, sp500_stress, width, label='S&P 500', color='firebrick', alpha=0.7)\n",
    "    ax4b.bar(x + width/2, basket_stress, width, label='Basket', color='green', alpha=0.7)\n",
    "    \n",
    "    # Add horizontal lines at zero\n",
    "    ax4b.axhline(0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # Add labels and customize\n",
    "    ax4b.set_title('Performance During Market Stress Periods', fontsize=14)\n",
    "    ax4b.set_ylabel('30-Day Return (%)', fontsize=12)\n",
    "    ax4b.set_xticks(x)\n",
    "    ax4b.set_xticklabels(periods)\n",
    "    ax4b.legend()\n",
    "    ax4b.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Calculate average outperformance during stress\n",
    "    avg_outperformance = sum(b-s for s, b in zip(sp500_stress, basket_stress)) / len(stress_results)\n",
    "    ax4b.annotate(f\"Average Outperformance: {avg_outperformance:.2f}%\", \n",
    "                 xy=(0.5, 0.05), xycoords='axes fraction', ha='center',\n",
    "                 fontsize=12, fontweight='bold', color='green' if avg_outperformance > 0 else 'firebrick')\n",
    "\n",
    "# Add summary table (text) at the bottom of the figure\n",
    "summary_text = (\n",
    "    \"RISK-RETURN SUMMARY:\\n\"\n",
    "    f\"• Basket Return: {metrics['Basket']['Annualized Return (%)']:.2f}% vs S&P 500: {metrics['S&P 500']['Annualized Return (%)']:.2f}%\\n\"\n",
    "    f\"• Basket Volatility: {metrics['Basket']['Volatility (%)']:.2f}% vs S&P 500: {metrics['S&P 500']['Volatility (%)']:.2f}%\\n\"\n",
    "    f\"• Sharpe Ratio: {metrics['Basket']['Sharpe Ratio']:.2f} vs {metrics['S&P 500']['Sharpe Ratio']:.2f}\\n\"\n",
    "    f\"• Risk-Adjusted Outperformance: {(metrics['Basket']['Sharpe Ratio']/metrics['S&P 500']['Sharpe Ratio']-1)*100:.1f}%\"\n",
    ")\n",
    "\n",
    "fig.text(0.5, 0.01, summary_text, fontsize=12, ha='center', va='bottom', \n",
    "         bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.97])  # Adjust for the summary text\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "plt.suptitle('Vital Industries Basket: Lower Volatility with Higher Returns', fontsize=16, y=0.99)\n",
    "plt.show()\n",
    "\n",
    "# Print detailed metrics table\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Annualized Return (%)', 'Annualized Volatility (%)', 'Sharpe Ratio', 'Max Drawdown (%)', \n",
    "               'Downside Deviation (%)', 'Positive Periods (%)', 'Negative Periods (%)'],\n",
    "    'Basket': [\n",
    "        f\"{metrics['Basket']['Annualized Return (%)']:.2f}\",\n",
    "        f\"{metrics['Basket']['Volatility (%)']:.2f}\",\n",
    "        f\"{metrics['Basket']['Sharpe Ratio']:.2f}\",\n",
    "        f\"{metrics['Basket']['Max Drawdown (%)']:.2f}\",\n",
    "        f\"{metrics['Basket']['Data'][metrics['Basket']['Data'] < 0].std() * np.sqrt(annual_factor) * 100:.2f}\",\n",
    "        f\"{(metrics['Basket']['Data'] > 0).mean() * 100:.1f}\",\n",
    "        f\"{(metrics['Basket']['Data'] < 0).mean() * 100:.1f}\"\n",
    "    ],\n",
    "    'S&P 500': [\n",
    "        f\"{metrics['S&P 500']['Annualized Return (%)']:.2f}\",\n",
    "        f\"{metrics['S&P 500']['Volatility (%)']:.2f}\",\n",
    "        f\"{metrics['S&P 500']['Sharpe Ratio']:.2f}\",\n",
    "        f\"{metrics['S&P 500']['Max Drawdown (%)']:.2f}\",\n",
    "        f\"{metrics['S&P 500']['Data'][metrics['S&P 500']['Data'] < 0].std() * np.sqrt(annual_factor) * 100:.2f}\",\n",
    "        f\"{(metrics['S&P 500']['Data'] > 0).mean() * 100:.1f}\",\n",
    "        f\"{(metrics['S&P 500']['Data'] < 0).mean() * 100:.1f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Detailed Risk-Return Metrics Comparison:\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Calculate the probability of outperformance over different time horizons\n",
    "horizons = [1, 3, 5, 10]  # years\n",
    "outperformance_df = pd.DataFrame(index=horizons, columns=['Probability of Outperformance (%)', 'Expected Excess Return (%)'])\n",
    "\n",
    "for years in horizons:\n",
    "    days = years * 252\n",
    "    basket_mean = metrics['Basket']['Data'].mean() * days\n",
    "    basket_vol = metrics['Basket']['Data'].std() * np.sqrt(days)\n",
    "    sp500_mean = metrics['S&P 500']['Data'].mean() * days\n",
    "    sp500_vol = metrics['S&P 500']['Data'].std() * np.sqrt(days)\n",
    "    \n",
    "    # Combined distribution of return difference\n",
    "    diff_mean = basket_mean - sp500_mean\n",
    "    diff_vol = np.sqrt(basket_vol**2 + sp500_vol**2 - 2*0.8*basket_vol*sp500_vol)  # Assuming 0.8 correlation\n",
    "    \n",
    "    # Probability of outperformance\n",
    "    prob = 1 - norm.cdf(0, diff_mean, diff_vol)\n",
    "    \n",
    "    outperformance_df.loc[years, 'Probability of Outperformance (%)'] = f\"{prob*100:.1f}\"\n",
    "    outperformance_df.loc[years, 'Expected Excess Return (%)'] = f\"{diff_mean*100:.1f}\"\n",
    "\n",
    "print(\"\\nProbability of Basket Outperforming S&P 500:\")\n",
    "print(outperformance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
